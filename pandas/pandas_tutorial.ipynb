{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A more in-depth look at pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Besides system files and neuroimages, you are guaranteed to encounter a lot of\n",
    "spreadsheets when you're doing data-analysis. Often, you will be confronted with\n",
    "scenarios involving making large-scale changes to spreadsheets, merging them, \n",
    "filtering, and all sorts of other tasks that are hard or impossible to do my hand.\n",
    "\n",
    "A great a library called Pandas is specifically built for interacting with spreadsheets in a \n",
    "(relatively) user-friendly way! \n",
    "\n",
    "This lesson will be all about using Pandas to interact with spreadsheets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# First, lets import pandas and a few other modules\n",
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Lets read in the results from our PyCourse survey and create a Pandas Dataframe out\n",
    "# of it. The spreadsheet is in .csv format. Loading a csv in Pandas is very easy:\n",
    "\n",
    "# load csv into a pandas dataframe\n",
    "df = pd.read_csv('pd_tutorial.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this will show you your whole data frame\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Also, if you just want to see the beginning of your DataFrame, you can do this:\n",
    "\n",
    "df.head()\n",
    "\n",
    "# Which takes up less space. You can see the end with df.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before I get into all the cool things we can do with out dataframe, I want to show you\n",
    "a few more points about loading Dataframes, and a few features of Dataframe objects\n",
    "\n",
    "First, this .csv import went very well -- the first row ended up as our Dataframe header as \n",
    "we wanted. However, sometimes the import doesn't go that well. Luckily, there are a few\n",
    "simple arguments that you can pass that can fix the problem. See the read_csv docstring\n",
    "to find out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pandas.read_csv?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I'll describe some of the useful arguments here:\n",
    "\n",
    "*Sep*: if your .csv is not comma-separated at all, but delimited by some other character, you\n",
    "can set that here. For example, it it was delimited by a ;, you would just type \n",
    "`read_csv(sheet,sep=';')`\n",
    "\n",
    "*delim_whitespace*: if set to True, the Dataframe will also uses whitespace (' ') as a sep.\n",
    "\n",
    "*header*: if you have no header (no column names), you can pass `header=None`. If you're column\n",
    "names are on a different row than the first, you can type `header = x`, where x is an int\n",
    "referring to the row # of your header. If you have a multi-index (more than one level of\n",
    "column names), you can pass a list of ints indicating which rows your different headers\n",
    "are\n",
    "\n",
    "*usecols*: if you only want to use some of the columns, but not all, you can pass a list of\n",
    "ints or strs indicating the column numbers or names you want to use\n",
    "\n",
    "As you can see, there are many others, but these are the ones you might use a lot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### pandas can load dataframes from many other formats as well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pd.read_excel?\n",
    "#pandas.read_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Some simple functions and methods from our dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to see the number of rows\n",
    "print('this spreadsheet has %s rows'%len(df))\n",
    "\n",
    "# or the number of rows and columns\n",
    "print('rows x columns = ',df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# There's also a nifty function that will tell you basic statistics about every column\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You can also get individual statistics if you like:\n",
    "\n",
    "df.mean()\n",
    "\n",
    "# Note that these are the only columns returned because these are the only columns with\n",
    "# all numbers in them. We'll fix that later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataframes have methods (functions, as you've seen above), but they also have\n",
    "# attributes that can be accessed. Two of the most important are the columns and\n",
    "# the index. Luckily, these are very intutive.\n",
    "\n",
    "print('the index of df is ',df.index)\n",
    "print('\\n')\n",
    "print('the columns of df are ',df.columns)\n",
    "print('\\n')\n",
    "\n",
    "# Notice how I do not give these (parentheses) because they are not functions, they\n",
    "# are attributes. Actually, they behave a lot like lists! As such, you can index and \n",
    "# slice them:\n",
    "print('the index of the 14th row is ',df.index[14])\n",
    "print('\\n')\n",
    "print('the 15th through 19th columns are ',df.columns[15:19])\n",
    "\n",
    "# As we'll see later, you can also directly modify these attributes in the same way you would\n",
    "# modify a list!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Indexing, Slicing and Querying\n",
    "\n",
    "There are *many* ways to to index and slice. It can get a bit confusing because\n",
    "there is a lot of redundancy and a lot of slight differences between methods.\n",
    "\n",
    "### You can easily print all values in a column. These approaches all have the same output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['What do you think of beards?']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df.columns[-2]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[:,'What do you think of beards?']\n",
    "# Purely label-location based indexer for selection by label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.iloc[:,-2]\n",
    "#Purely integer-location based indexing for selection by position"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.ix[:,'What do you think of beards?']\n",
    "# OR\n",
    "df.ix[:,-2]\n",
    "# A primarily label-location based indexer, with integer position fallback"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's just make a mental note that a dataframe is a bunch of series together\n",
    "So any column or row could be a series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# So you can slice a column from the df and save it into its own variable that is a series\n",
    "ser = df.ix[:,df.columns[-2]]\n",
    "print(ser)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# These series have their own set of functions. See below:\n",
    "print(ser.unique())\n",
    "print('\\n')\n",
    "print(ser.describe())\n",
    "print('\\n')\n",
    "print(ser.hasnans)\n",
    "print('\\n')\n",
    "print(ser.value_counts())\n",
    "print('\\n')\n",
    "\n",
    "# Actually, they have almost every function of a full dataframe!\n",
    "\n",
    "# They can also be easily converted to lists\n",
    "print(ser.tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By the way, you can use the above methods to print multiple Series at once by putting your column labels inside of a list!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I'll do it below, but I'll just print the beginning in order to save space\n",
    "\n",
    "df[[df.columns[-2],df.columns[34]]].head()\n",
    "\n",
    "# Be aware of all these different [square brackets] and how each set is doing something\n",
    "# different in the line above. The outer set is used to index df, the middle set is used\n",
    "# to indicate a list is being formed, and the inner sets are used to index df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This will give the same output as above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[['What do you think of beards?','Use an emoji to describe how you feel about emojis']].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Slicing rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Slicing rows (rather than columns) is just as simple and also include redundant functionality\n",
    "# I will use two redundant commands to print every value for the 10th row\n",
    "\n",
    "# Again, I used head() to save space\n",
    "\n",
    "df.iloc[10]\n",
    "df.ix[10].head()\n",
    "\n",
    "# Just like with slicing columns, a slice taken along the index (a row) is also a pandas Series\n",
    "# and also retains all the functions and methods of a pandas DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Like above, you can pass slices from the index, so let's get the 8th, 9th, and 10th rows\n",
    "df.ix[8:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are also ways to get exact data points from within your Dataframe. As with\n",
    "indexing and slicing, there are several ways to go about this. I prefer the .ix\n",
    "attribute. You need only to pass it the number (or name) of the row and the name\n",
    "(or number) of the column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.ix[5:10,'What operating system do you most prefer?']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In much the same fashion, you can select exact slices that you want to pull out of\n",
    "# the data. Here, I will print the values in the 12th-14th columns for the 2nd-4th \n",
    "# rows.\n",
    "\n",
    "df.ix[2:4,12:14]\n",
    "\n",
    "# And just like the other attributes I've shown you, such slices are actually pandas\n",
    "# Series and therefore come with all of the functions of a Series"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Querying"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# When you pass simple Truth statements to a pandas Series, it does not give you a single\n",
    "# Boolean response, but rather a response for each value in the Series\n",
    "\n",
    "homebodies = df['How many continents have you visited']\n",
    "homebodies < 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You can use the & sign to include additional arguments in your query\n",
    "\n",
    "driving = df['How good do you think you are a driving (3 is average)']\n",
    "sports = df['How good are you at sports?']\n",
    "overconfident = (sports > 4) & (driving > 4)\n",
    "overconfident"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### You can also slice a dataframe using a query. \n",
    "Here I'll return all dataframe entries that fit the query for overconfidence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[overconfident]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[['Can you roll your tongue?','Do you have any food allergies or intolerances?']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(df['Can you roll your tongue?'] == 'Yes') & (df['Do you have any food allergies or intolerances?'] == 'No')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also use OR statements with `|`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "(df['Can you roll your tongue?'] == 'Yes') | (df['Do you have any food allergies or intolerances?'] == 'No')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# There is more you can do with querying, but for now, I'll teach you one last trick\n",
    "# You can have query based on whether a certain response is within a list of values\n",
    "# Here's how it works\n",
    "\n",
    "primary_colors = ['red','blue','yellow']\n",
    "df[df[\"What color is the shirt/dress/upper-body-clothing you're wearing right now, if any?\"].isin(primary_colors)]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modifying dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### MODIFYING DATAFRAMES #######\n",
    "\n",
    "# Before I show you how to modify DataFrames, it would first be good to learn how to\n",
    "# \"save\" them, as its always good to save before modifying. \n",
    "\n",
    "# The most traditional way of \"saving\" a DataFrame is to write it to a file, either\n",
    "# a new file (like Save as...) or an existing file (like Save)\n",
    "\n",
    "# This is very easy with Python. You can save to a number of different formats:\n",
    "# df.to_\n",
    "\n",
    "# Let's overwrite the file we already have:\n",
    "print(sheet)\n",
    "df.to_csv(sheet) # that's it. Its saved!\n",
    "\n",
    "# You can also edit the characteristics of the saved file -- see the docstring for details"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### let's make a copy of our old dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_df = df.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the above function will make a new dataframe that is immutable, so no information will be shared between `df` and `n_df`, meaning changing one will NOT change the other."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Whereas, making a \"copy\" like the way it will be done below will make a mutable object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "newdf = df\n",
    "print('here is the value at row 1, column 1 for df and newdf before modifying newdf')\n",
    "print('for df: ', df.iloc[1,1])\n",
    "print('for newdf: ', newdf.iloc[1,1])\n",
    "print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So changing `newdf` will change the original `df` !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "newdf.iloc[1,1] = 'changed!!'\n",
    "print('here is the value at row 1, column 1 for df and newdf after modifying newdf')\n",
    "print('for df: ', df.iloc[1,1])\n",
    "print('for newdf: ', newdf.iloc[1,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So let's work with the immutable independent copy we made"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modifying some value in your dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modifying DataFrames is fairly straightforward. As you can see, we can modify \n",
    "DataFrame values by just setting them:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('old codename: ', n_df.loc[1,'Enter your codename here'])\n",
    "n_df.loc[1,'Enter your codename here'] = 'wonder woman'\n",
    "print('new codename: ', n_df.loc[1,'Enter your codename here'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modifying entire rows and columns works in the same way. Let's say you wanted to update\n",
    "# a subject's information (i.e. change an entire row). As long as your input dimensions\n",
    "# match the dimensions of the row, it will work fine:\n",
    "\n",
    "new_info = range(len(newdf.columns)) # creating a range the same length as the # of columns\n",
    "n_df.iloc[5] = new_info # replacing the 5th row with this range of consecutive numbers\n",
    "n_df.iloc[5].head() # show"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dropping columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's get rid of the column called \"Timestamp\"\n",
    "n_df.drop(labels='Timestamp',axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note the argument `inplace=True` will make it so that the column will be permanently dropped. Otherwise the default is `inplace=False` and will just print the dataframe without that column"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dropping rows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's say we want to get rid of data for all people who identified as \"PhD Student\" as their position"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to set the index to that column first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_df.set_index('What is your position?', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's get rid of any row where \"PhD Student\" appears in the index\n",
    "n_df.drop(labels='PhD Student', axis=0)\n",
    "\n",
    "# but let's not make it a permanent thing because PhD students are great"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's how to reset the index back to what it was"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_df.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dropping NaNs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's get rid of everyone who didn't provide a codename\n",
    "n_df.dropna(subset=['Enter your codename here'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating a new column from a current column"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's say you want to create dummy variables for a new column from a column where the answers are \"Yes\" and \"No\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`iterrows` is a handy method for this job as it iterates over a DataFrame rows as (index, Series) pairs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i,row in n_df.iterrows():\n",
    "    ans = row['Can you roll your tongue?']\n",
    "    if ans == 'Yes':\n",
    "        n_df.loc[i, 'tongue_dummy'] = 1\n",
    "    if ans == 'No':\n",
    "        n_df.loc[i, 'tongue_dummy'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding brand new rows or columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding new rows and columns is also pretty easy. Have a look:\n",
    "\n",
    "new_col = range(len(df.index))\n",
    "n_df.loc[:,'new_columns'] = new_col\n",
    "n_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You can add new rows (in this case, subjects) using the same approach. \n",
    "\n",
    "# set the index to codenames first\n",
    "n_df.set_index('Enter your codename here', inplace=True)\n",
    "\n",
    "new_codenames = ['twist_the_dutchie','bitterballer','Feyenoord_sux']\n",
    "for cn in new_codenames:\n",
    "    n_df.loc[cn] = np.full(len(n_df.columns),np.nan)\n",
    "    \n",
    "n_df.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# for more info!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "There is *SO* much more you can do with pandas that I will not get into for right now.\n",
    "But the pandas website is a great resource. Check out for example these pages:\n",
    "\n",
    "* Cookbook: http://pandas.pydata.org/pandas-docs/stable/cookbook.html\n",
    "* Tutorials: http://pandas.pydata.org/pandas-docs/stable/tutorials.html\n",
    "* Useful statistics: http://pandas.pydata.org/pandas-docs/stable/computation.html\n",
    "* Merging spreadsheets: http://pandas.pydata.org/pandas-docs/stable/merging.html <- my personal favourite\n",
    "* Installation guide: https://pandas.pydata.org/pandas-docs/stable/install.html\n",
    "* All the documentation: https://pandas.pydata.org/pandas-docs/stable/index.html\n",
    "\n",
    "Slack me with any questions @angelatam\n",
    "\n",
    "Thanks to Jake Vogel for contibuting to this notebook\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
