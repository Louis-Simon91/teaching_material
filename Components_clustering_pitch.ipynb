{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Components analysis + clustering\n",
    "* Dimension reduction (PCA)\n",
    "* Understanding data structure (clustering)\n",
    "* Decomposing sources of variance (ICA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# load some data\n",
    "import os\n",
    "import pandas\n",
    "import numpy as np\n",
    "\n",
    "wdir = os.path.join(os.getcwd(),'stuff')\n",
    "if not os.path.isdir(wdir) and os.path.isfile(os.path.join(os.getcwd(),'stuff.tar.gz')):\n",
    "    os.system('tar -xvzf %s'%os.path.join(os.getcwd(),'stuff.tar.gz'))\n",
    "\n",
    "wdir = os.path.join(os.getcwd(),'stuff')\n",
    "df = pandas.read_csv(os.path.join(wdir,'MAIN_hippocampus_sample_info.csv'))\n",
    "jnk = np.load(os.path.join(wdir,'gxp.npz'))\n",
    "gxp = pandas.DataFrame(jnk['arr_0'].T)\n",
    "gxp.drop(gxp.index[0],inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is Allen Human Brain Atlas data. Specifically, it is a set of 170 brain samples inside the hippocampus (from 6 different donors). For each sample, we have microarray data summarizing the normalized expression level of 60k probes, each probe corresponding to a gene"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gxp.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#gxp.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Let's reduce the data with PCA\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "pca = PCA(n_components = 170, random_state=123)\n",
    "mod = pca.fit(gxp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# how much variance can we explain per component\n",
    "import matplotlib.pyplot as plt\n",
    "plt.close()\n",
    "plt.plot(mod.explained_variance_ratio_)\n",
    "plt.xlabel('Number of components')\n",
    "plt.ylabel('Percentage of total variance explained')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# lets zoom in a bit\n",
    "plt.close()\n",
    "plt.plot(mod.explained_variance_ratio_[:25])\n",
    "plt.xlabel('Number of components')\n",
    "plt.ylabel('Percentage of total variance explained')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It looks like we can explain quite a bit of the total variance of the data using a fraction of the components..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# How much variance can we explain with just (arbitrarily) 25 components?\n",
    "pca25 = PCA(n_components = 25, random_state=123)\n",
    "mod = pca25.fit(gxp)\n",
    "sum(mod.explained_variance_ratio_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Now lets transform our data\n",
    "gxp_PCA = mod.transform(gxp)\n",
    "gxp_PCA.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, instead of having 60k features, we have 25 features, but we're explaining 3/4 of the total variance of the 60k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# the component matrix is available to understand the importance of features to the components\n",
    "mod.components_.shape\n",
    "\n",
    "# and you can always back-transform the data\n",
    "# mod.inverse_transform"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Use clustering to explore the natural structure of our data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "# Using a simple clustering plot, we can look at how samples group \n",
    "# based on covaryiance of features\n",
    "plt.close()\n",
    "sns.clustermap(gxp_PCA, col_cluster=False, row_cluster=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the sklearn.cluster module has a number of clustering algorithms that are accessible and simple to use\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cluster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# as an example, I'll run quick k-means clustering on the same data as above\n",
    "# note that I'm setting the random state -- important because this a stochastic process\n",
    "kmean = cluster.KMeans(n_clusters=4, random_state=123)\n",
    "kmeans_gxp = kmean.fit(gxp_PCA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# we can easy retrieve the resulting cluster labels for each input sample\n",
    "kmeans_gxp.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.close()\n",
    "pandas.crosstab(pandas.Series(kmeans_gxp.labels_),\n",
    "               df.structure_acronym\n",
    "               ).plot.bar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Here, we'll use a fancy clustering algorithm to reduce the date further in order\n",
    "# to visualize the natural clustering of the data in three dimensions\n",
    "import umap\n",
    "nbr = 5\n",
    "dist = 0.01\n",
    "embedding = umap.UMAP(n_components=3, n_neighbors=nbr, min_dist=dist, random_state=123\n",
    "                     ).fit_transform(gxp_PCA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# to see if the hippocampal samples cluster based on the subfield they belong to, we'll label\n",
    "# each sample by which subfield it belongs to\n",
    "code = dict(zip(df.structure_acronym.unique(),\n",
    "               range(len(df.structure_acronym.unique()))))\n",
    "labs = [code[x] for x in df.structure_acronym.tolist()]\n",
    "lmap = dict(zip(code.values(),code.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# and now we'll plot the relationship\n",
    "import numpy as np\n",
    "import plotly\n",
    "\n",
    "traces = list()\n",
    "for lab in np.unique(labs):\n",
    "    l_index = [x for x in range(len(labs)) if labs[x] == lab]\n",
    "    l_embed = embedding[l_index]\n",
    "#     color_str = str(int('0x' + color_dict[lab][1:3].upper(),16)) + ',' + \\\n",
    "#                    str(int('0x' + color_dict[lab][3:5].upper(),16)) + ',' + \\\n",
    "#                    str(int('0x' + color_dict[lab][5:7].upper(),16))\n",
    "    #color_str = plt.cm.tab10.colors[lab]\n",
    "    color_str = 'rgba %s'%str(tuple([x - 0.0000001 for x in plt.cm.tab10(lab) if x > 0]))\n",
    "    temp_trace = plotly.graph_objs.Scatter3d(x=l_embed[:,0],\n",
    "                                            y = l_embed[:,1],\n",
    "                                            z = l_embed[:,2],\n",
    "                                            name = lmap[lab],\n",
    "                                            mode = 'markers',\n",
    "                                            marker = dict(size=5,\n",
    "                                                          color=color_str\n",
    "                                                         )\n",
    "                                            )\n",
    "    traces.append(temp_trace)\n",
    "\n",
    "layout = plotly.graph_objs.Layout(margin = dict(l=0,r=0,b=0,t=0))\n",
    "\n",
    "fig = plotly.graph_objs.Figure(data=traces, layout=layout)\n",
    "plotly.offline.plot(fig, filename='clusters.html')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# here is a non-interactive version of the same thing\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "plt.close()\n",
    "fig = plt.figure(figsize=(8,8))\n",
    "ax = Axes3D(fig)\n",
    "ax.scatter(embedding[:,0], embedding[:,1], embedding[:,2], c = labs, s=20)\n",
    "plt.show()\n",
    "#plt.savefig(os.path.join(outdir,'umap_%s_%s.pdf'%(nbr,dist)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Documentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "sklearn clustering documentaton: http://scikit-learn.org/stable/modules/clustering.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "sklearn signal decomposition documentation: http://scikit-learn.org/stable/modules/decomposition.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "installing sklearn: http://scikit-learn.org/stable/install.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "umap: https://github.com/lmcinnes/umap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you have any further questions or think I can be of help, my brainhack slack handle is jvogel"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:py3]",
   "language": "python",
   "name": "conda-env-py3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
